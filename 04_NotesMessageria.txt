=======================================================================================================================
JMS e ActiveMQ: Mensageria com Java.

Entendendo o Kafka
(série de 6 partes)
O que é o Apache Kafka
Rodando o Apache Kafka localmente
Enviando Mensagens
Recebendo Mensagens
Anatomia de um Tópico
Log Cleanup no Kafka
Aprofundando um pouco mais no Kafka, precisamos entender o que é um Tópico e como ele se comporta. Tópico é um dos conceitos mais básicos do Kafka! Está presente em quase tudo.

Sobre Tópico podemos falar:

Um Producer envia uma mensagem para um Tópico.
Um Consumer se subscreve a um, ou mais, Tópicos.
Um Tópico pode ser subscrito por um ou mais Consumer.

Nomenclatura
Daqui pra frente, precisamos definir alguns nomes. Sempre que falamos de uma instalação do Kafka, estamos falando de um broker Kafka, isso significa, um servidor ou uma instância. Esse broker faz parte de um conjunto maior, que é o cluster Kafka. O cluster é um conjunto de brokers que atuam como se fossem um sistema só. Os dados fazem parte do cluster e podem estar em um ou mais broker.

Criação
Vamos olhar para criação de um Tópico para tentar entender mais:

.\bin\windows\kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
Dada a linha acima podemos identificar alguns parâmetros para criação de um tópico:

bootstap-server: Mesmo já especificado na criação do Consumer e Producer. Identitica o cluster onde será criado o tópico. É formado pelo ip:porta de cada broker separado por virgula.
partitions: Um Tópico é dividido em partições. Estas podem estar no mesmo broker ou não. Normalmente elas são distribuídas entre brokers.
replication-factor: Número mínimo de vezes que os dados desse tópico serão replicados. Caso tenha um fator de replicação maior que um, cada partição será replicada em outro broker.
Anatomia de um Tópico

Podemos assim definir que um Tópico é distribuído entre partições. Cada partição é uma armazena parte das mensagens enviadas, estas, por sua vez, são distribuídas entre as partições de acordo com a chave associada a ela.

As mensagens são armazenadas sequencialmente dentro de uma partição, assim, cada mensagem terá associada um número de partição e um _offset. Este offset é a posição da mensagem dentro da partição.

Distribuição
Ao se criar um tópico, as partições do mesmo são distribuídas entre os brokers. 
Não necessariamente todas as mensagens serão armazenadas juntas.
Cada mensagem é envida para apenas uma partição, essa distribuição é feita baseada na chave associada a mensagem. Assim, mensagens com a mesma chave, irão para a mesma partição. Isso é importante!

Estrutura de Arquivos
Uma partição é um arquivo de log. 
Quando o broker recebe uma mensagem, ela é adicionada ao final da partição. A essa mensagem é associado um offset.
Com isso para se localizar exatamente onde uma mensagem está armazenada é preciso observar os valores:

topic
partition
offset
Todos esses valores estão presentes em RecordMetadata e ConsumerRecord.

Replicação
No Kafka, é possível haver replicação de dados. Para isso é preciso que exista ao menos um broker configurado.

Utilizando o parametro replication-factor da criação do tópico, cada partição será replicada em um broker diferente. 
Assim o valor máximo para esse parâmetro é o número de brokers existente.

Ordenação das Mensagens
As mensagens de uma partição serão enviadas a apenas um consumer, não haverá mais de um consumer para uma partição. Assim, as mensagens da partição serão entregues em ordem cronológica.

Vale lembrar que o Kafka não garante a ordenação global das mensagens enviadas. Mas dada uma boa escolha da chave das mensagens, é possível garantir a ordenação das mensagens associadas.

Por exemplo, se estamos consumindo mensagens de acesso de usuários. 
Podemos usar o id do usuário como chave, assim todas as mensagem de um mesmo usuário serão consumidas em ordem cronológica, evitando erros de consistência dos dados.

Entendendo o Kafka(série de 6 partes)

O que é o Apache Kafka
Rodando o Apache Kafka localmente
Enviando Mensagens
Recebendo Mensagens
Anatomia de um Tópico
Log Cleanup no Kafka

Apache Camel
O Apache Camel é um framework de integração baseado em padrões empresariais de integração (EIP). Traduzindo em termos simples, ele pretende simplificar a integração entre sistemas. O fato de ser baseado em padrões é o que o torna uma das melhores opções do mercado. 
Padrões, como sabemos, representam as melhores práticas ou a melhor forma de se fazer alguma coisa. Padrões também facilitam a comunicação entre as pessoas e, além disso, são reaproveitáveis, trazendo maior produtividade e diminuindo o custo de propriedade.

Independente de todo esse discurso empresarial chato, desenvolver com Apache Camel pode ser extremamente divertido. Com poucas linhas de código ou configuração, podemos processar arquivos, processá-los em paralelo, invocar Web Services, publicar eventos em uma fila JMS e muito mais.

JMS e ActiveMQ: Mensageria com Java.

Entendendo o Kafka
(série de 6 partes)
O que é o Apache Kafka
Rodando o Apache Kafka localmente
Enviando Mensagens
Recebendo Mensagens
Anatomia de um Tópico
Log Cleanup no Kafka
Aprofundando um pouco mais no Kafka, precisamos entender o que é um Tópico e como ele se comporta. Tópico é um dos conceitos mais básicos do Kafka! Está presente em quase tudo.

Sobre Tópico podemos falar:

Um Producer envia uma mensagem para um Tópico.
Um Consumer se subscreve a um, ou mais, Tópicos.
Um Tópico pode ser subscrito por um ou mais Consumer.

Nomenclatura
Daqui pra frente, precisamos definir alguns nomes. Sempre que falamos de uma instalação do Kafka, estamos falando de um broker Kafka, isso significa, um servidor ou uma instância. Esse broker faz parte de um conjunto maior, que é o cluster Kafka. O cluster é um conjunto de brokers que atuam como se fossem um sistema só. Os dados fazem parte do cluster e podem estar em um ou mais broker.

Criação
Vamos olhar para criação de um Tópico para tentar entender mais:

.\bin\windows\kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
Dada a linha acima podemos identificar alguns parâmetros para criação de um tópico:

bootstap-server: Mesmo já especificado na criação do Consumer e Producer. Identitica o cluster onde será criado o tópico. É formado pelo ip:porta de cada broker separado por virgula.
partitions: Um Tópico é dividido em partições. Estas podem estar no mesmo broker ou não. Normalmente elas são distribuídas entre brokers.
replication-factor: Número mínimo de vezes que os dados desse tópico serão replicados. Caso tenha um fator de replicação maior que um, cada partição será replicada em outro broker.
Anatomia de um Tópico

Podemos assim definir que um Tópico é distribuído entre partições. Cada partição é uma armazena parte das mensagens enviadas, estas, por sua vez, são distribuídas entre as partições de acordo com a chave associada a ela.

As mensagens são armazenadas sequencialmente dentro de uma partição, assim, cada mensagem terá associada um número de partição e um _offset. Este offset é a posição da mensagem dentro da partição.

Distribuição
Ao se criar um tópico, as partições do mesmo são distribuídas entre os brokers. 
Não necessariamente todas as mensagens serão armazenadas juntas.
Cada mensagem é envida para apenas uma partição, essa distribuição é feita baseada na chave associada a mensagem. Assim, mensagens com a mesma chave, irão para a mesma partição. Isso é importante!

Estrutura de Arquivos
Uma partição é um arquivo de log. 
Quando o broker recebe uma mensagem, ela é adicionada ao final da partição. A essa mensagem é associado um offset.
Com isso para se localizar exatamente onde uma mensagem está armazenada é preciso observar os valores:

topic
partition
offset
Todos esses valores estão presentes em RecordMetadata e ConsumerRecord.

Replicação
No Kafka, é possível haver replicação de dados. Para isso é preciso que exista ao menos um broker configurado.

Utilizando o parametro replication-factor da criação do tópico, cada partição será replicada em um broker diferente. 
Assim o valor máximo para esse parâmetro é o número de brokers existente.

Ordenação das Mensagens
As mensagens de uma partição serão enviadas a apenas um consumer, não haverá mais de um consumer para uma partição. Assim, as mensagens da partição serão entregues em ordem cronológica.

Vale lembrar que o Kafka não garante a ordenação global das mensagens enviadas. Mas dada uma boa escolha da chave das mensagens, é possível garantir a ordenação das mensagens associadas.

Por exemplo, se estamos consumindo mensagens de acesso de usuários. 
Podemos usar o id do usuário como chave, assim todas as mensagem de um mesmo usuário serão consumidas em ordem cronológica, evitando erros de consistência dos dados.

Entendendo o Kafka(série de 6 partes)

O que é o Apache Kafka
Rodando o Apache Kafka localmente
Enviando Mensagens
Recebendo Mensagens
Anatomia de um Tópico
Log Cleanup no Kafka

Apache Camel
O Apache Camel é um framework de integração baseado em padrões empresariais de integração (EIP). Traduzindo em termos simples, ele pretende simplificar a integração entre sistemas. O fato de ser baseado em padrões é o que o torna uma das melhores opções do mercado. 
Padrões, como sabemos, representam as melhores práticas ou a melhor forma de se fazer alguma coisa. Padrões também facilitam a comunicação entre as pessoas e, além disso, são reaproveitáveis, trazendo maior produtividade e diminuindo o custo de propriedade.

Independente de todo esse discurso empresarial chato, desenvolver com Apache Camel pode ser extremamente divertido. Com poucas linhas de código ou configuração, podemos processar arquivos, processá-los em paralelo, invocar Web Services, publicar eventos em uma fila JMS e muito mais.


